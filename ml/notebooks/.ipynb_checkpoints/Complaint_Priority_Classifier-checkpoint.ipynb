{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Complaint Priority Classifier\n",
                "\n",
                "This notebook uses a local Ollama model (`qwen2.5:3b-instruct`) to classify complaints into High, Medium, or Low priority."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import requests\n",
                "import json\n",
                "\n",
                "# Configuration\n",
                "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
                "MODEL_NAME = \"qwen2.5:3b-instruct\"\n",
                "\n",
                "# System Prompt Definition\n",
                "SYSTEM_PROMPT = \"\"\"\n",
                "You are NOT a chatbot.\n",
                "You are NOT an assistant.\n",
                "You are a strict text classification model.\n",
                "\n",
                "Your ONLY task is to analyze the complaint_text and return exactly ONE word from the following list:\n",
                "\n",
                "High\n",
                "Medium\n",
                "Low\n",
                "\n",
                "You must follow these rules strictly:\n",
                "- Output ONLY one word.\n",
                "- Do NOT explain.\n",
                "- Do NOT generate code.\n",
                "- Do NOT provide reasoning.\n",
                "- Do NOT repeat the complaint.\n",
                "- Do NOT add punctuation.\n",
                "- Do NOT add extra words.\n",
                "- Do NOT say anything before or after the answer.\n",
                "\n",
                "Classification Rules:\n",
                "\n",
                "High:\n",
                "- Essential services affected (water, electricity, hospital access, sewage overflow)\n",
                "- Public safety risk\n",
                "- Health hazards\n",
                "- Road completely blocked\n",
                "- Fire, flooding, major damage\n",
                "- Large number of people affected\n",
                "- Emergency situations\n",
                "\n",
                "Medium:\n",
                "- Local inconvenience\n",
                "- Parking issues\n",
                "- Noise complaints\n",
                "- Minor road damage\n",
                "- Streetlight not working\n",
                "- Garbage collection delay in small area\n",
                "- Issues affecting limited number of people\n",
                "\n",
                "Low:\n",
                "- Personal disputes\n",
                "- Very minor cleanliness issues\n",
                "- Small inconvenience affecting very few people\n",
                "- Non-urgent or informational complaints\n",
                "\n",
                "Examples:\n",
                "\n",
                "complaint_text = \"no water supply today in my area\"\n",
                "Output: High\n",
                "\n",
                "complaint_text = \"unknown car parking in front of my home\"\n",
                "Output: Medium\n",
                "\n",
                "complaint_text = \"neighbor playing loud music during afternoon\"\n",
                "Output: Medium\n",
                "\n",
                "complaint_text = \"small crack in pavement near my gate\"\n",
                "Output: Low\n",
                "\"\"\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def classify_complaint(complaint_text):\n",
                "    \"\"\"\n",
                "    Classifies the complaint text using the local Ollama model.\n",
                "    \"\"\"\n",
                "    payload = {\n",
                "        \"model\": MODEL_NAME,\n",
                "        \"messages\": [\n",
                "            { \"role\": \"system\", \"content\": SYSTEM_PROMPT },\n",
                "            { \"role\": \"user\", \"content\": f\"complaint_text = \\\"{complaint_text}\\\"\" }\n",
                "        ],\n",
                "        \"stream\": False,\n",
                "        \"options\": {\n",
                "            \"temperature\": 0.0  # Deterministic output\n",
                "        }\n",
                "    }\n",
                "    \n",
                "    try:\n",
                "        response = requests.post(OLLAMA_URL, json=payload)\n",
                "        response.raise_for_status()\n",
                "        # The response structure depends on the endpoint. For /api/chat it's message.content\n",
                "        # For /api/generate it's response\n",
                "        result = response.json()\n",
                "        # Ollama /api/chat response: { \"model\": \"...\", \"created_at\": \"...\", \"message\": { \"role\": \"assistant\", \"content\": \"...\" }, ... }\n",
                "        if \"message\" in result:\n",
                "            priority = result[\"message\"][\"content\"].strip()\n",
                "        else:\n",
                "            # Fallback if using /api/generate structure (unlikely given URL but safe to check)\n",
                "            priority = result.get(\"response\", \"Error: Unexpected response format\").strip()\n",
                "            \n",
                "        return priority\n",
                "    except requests.exceptions.RequestException as e:\n",
                "        return f\"Error: {e}\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example Usage\n",
                "examples = [\n",
                "    \"The main water pipe burst and the street is flooding!\",\n",
                "    \"There is a pothole on 5th avenue.\",\n",
                "    \"My neighbor's dog barks at night.\"\n",
                "]\n",
                "\n",
                "print(f\"Testing Model: {MODEL_NAME}\\n\")\n",
                "\n",
                "for complaint in examples:\n",
                "    print(f\"Complaint: {complaint}\")\n",
                "    priority = classify_complaint(complaint)\n",
                "    print(f\"Priority: {priority}\\n\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Interactive Loop\n",
                "print(\"Complaint Priority Classifier (Type 'exit' to quit)\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "while True:\n",
                "    user_input = input(\"\\nEnter complaint text: \")\n",
                "    if user_input.lower() in ['exit', 'quit']:\n",
                "        break\n",
                "    \n",
                "    if not user_input.strip():\n",
                "        continue\n",
                "        \n",
                "    priority = classify_complaint(user_input)\n",
                "    print(f\"Priority: {priority}\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}